{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ddb7c8c6",
   "metadata": {},
   "source": [
    "# Hospital Readmission Prediction Demo with XGBoost and SHAP\n",
    "\n",
    "This notebook demonstrates how to:\n",
    "1. Generate synthetic patient readmission data\n",
    "2. Train an XGBoost model to predict readmission risk\n",
    "3. Evaluate model performance\n",
    "4. Interpret predictions using SHAP values\n",
    "5. Run unit tests to validate the model pipeline\n",
    "\n",
    "The goal is to predict which patients are likely to be readmitted within 30 days of discharge."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a15f063",
   "metadata": {},
   "source": [
    "## 1. Setup Dependencies\n",
    "\n",
    "First, we'll import all required libraries. Make sure you have installed:\n",
    "```bash\n",
    "pip install xgboost shap pytest scikit-learn pandas numpy matplotlib\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5a2b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import shap\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import pytest\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5e7981",
   "metadata": {},
   "source": [
    "## 2. Generate Synthetic Patient Data\n",
    "\n",
    "We'll create a synthetic dataset that mimics real patient data with features like:\n",
    "- Demographics (age, sex)\n",
    "- Prior utilization (admissions, ED visits)\n",
    "- Clinical factors (Charlson score, lab flags, medication count)\n",
    "- Length of stay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b379c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_synthetic_data(n=5000, seed=RANDOM_STATE):\n",
    "    rng = np.random.RandomState(seed)\n",
    "    \n",
    "    # Generate features\n",
    "    data = {\n",
    "        'age': rng.normal(65, 16, n).clip(18, 95).astype(int),\n",
    "        'sex': rng.binomial(1, 0.52, n),  # 1=male, 0=female\n",
    "        'prior_adm_6m': rng.poisson(0.6, n),\n",
    "        'ed_visits_6m': rng.poisson(0.8, n),\n",
    "        'charlson': rng.poisson(2.0, n),\n",
    "        'labs_flag': rng.binomial(1, 0.15, n),\n",
    "        'med_count': rng.poisson(5, n),\n",
    "        'length_of_stay': rng.exponential(3.0, n).clip(1, 30)\n",
    "    }\n",
    "    \n",
    "    # Calculate risk score and generate label\n",
    "    risk_score = (\n",
    "        0.02 * (data['age'] - 65) +\n",
    "        0.6 * (data['prior_adm_6m'] > 0) +\n",
    "        0.4 * (data['ed_visits_6m'] > 1) +\n",
    "        0.3 * data['charlson'] / (data['charlson'].max() + 1) +\n",
    "        0.05 * data['med_count'] +\n",
    "        0.1 * (data['length_of_stay'] > 5) +\n",
    "        rng.normal(0, 0.6, n)\n",
    "    )\n",
    "    \n",
    "    # Convert to probability and binary outcome\n",
    "    prob = 1 / (1 + np.exp(-risk_score))\n",
    "    data['readmit_30d'] = (rng.uniform(0, 1, n) < prob * 0.4).astype(int)\n",
    "    \n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Generate dataset\n",
    "df = generate_synthetic_data()\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "print(\"\\nFeature summary:\")\n",
    "print(df.describe().round(2))\n",
    "print(\"\\nReadmission rate:\", df['readmit_30d'].mean().round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aade72a4",
   "metadata": {},
   "source": [
    "## 3. Prepare Data for Modeling\n",
    "\n",
    "Split the data into training and test sets, then scale the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c80dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split features and target\n",
    "X = df.drop(columns=['readmit_30d'])\n",
    "y = df['readmit_30d']\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=RANDOM_STATE, stratify=y\n",
    ")\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"Training set shape:\", X_train.shape)\n",
    "print(\"Test set shape:\", X_test.shape)\n",
    "print(\"Readmission rate in train:\", y_train.mean().round(3))\n",
    "print(\"Readmission rate in test:\", y_test.mean().round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c803328",
   "metadata": {},
   "source": [
    "## 4. Train XGBoost Model\n",
    "\n",
    "We'll use XGBoost with parameters tuned for interpretability (limited depth) while maintaining good performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61afec73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize XGBoost classifier\n",
    "xgb_params = {\n",
    "    'max_depth': 4,  # Limit depth for interpretability\n",
    "    'learning_rate': 0.1,\n",
    "    'n_estimators': 100,\n",
    "    'min_child_weight': 5,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'objective': 'binary:logistic',\n",
    "    'random_state': RANDOM_STATE\n",
    "}\n",
    "\n",
    "model = xgb.XGBClassifier(**xgb_params)\n",
    "\n",
    "# Train the model\n",
    "model.fit(\n",
    "    X_train_scaled, \n",
    "    y_train,\n",
    "    eval_set=[(X_test_scaled, y_test)],\n",
    "    eval_metric='auc',\n",
    "    early_stopping_rounds=10,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "y_pred_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Show confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f7a2f0",
   "metadata": {},
   "source": [
    "## 5. SHAP Explanations\n",
    "\n",
    "Calculate SHAP values to understand feature importance and their impact on predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3fab93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate SHAP values\n",
    "explainer = shap.TreeExplainer(model)\n",
    "shap_values = explainer.shap_values(X_test_scaled)\n",
    "\n",
    "# Create SHAP summary plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "shap.summary_plot(shap_values, X_test_scaled, feature_names=X.columns, show=False)\n",
    "plt.title(\"SHAP Feature Importance\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Show SHAP feature importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance': np.abs(shap_values).mean(0)\n",
    "})\n",
    "feature_importance = feature_importance.sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\nFeature Importance Ranking:\")\n",
    "print(feature_importance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb272afa",
   "metadata": {},
   "source": [
    "## 6. Individual Patient Explanations\n",
    "\n",
    "Let's look at SHAP explanations for individual high-risk patients to understand what drives their predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d3dcf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get high-risk patients\n",
    "high_risk_idx = np.where(y_pred_proba > 0.7)[0]\n",
    "if len(high_risk_idx) > 0:\n",
    "    # Plot SHAP values for first high-risk patient\n",
    "    patient_idx = high_risk_idx[0]\n",
    "    \n",
    "    plt.figure(figsize=(10, 4))\n",
    "    shap.force_plot(\n",
    "        explainer.expected_value,\n",
    "        shap_values[patient_idx,:],\n",
    "        X_test_scaled[patient_idx,:],\n",
    "        feature_names=X.columns,\n",
    "        matplotlib=True,\n",
    "        show=False\n",
    "    )\n",
    "    plt.title(\"SHAP Force Plot for High-Risk Patient\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Show patient details\n",
    "    print(\"\\nHigh-risk patient details:\")\n",
    "    patient_data = X_test.iloc[patient_idx]\n",
    "    for feature, value in patient_data.items():\n",
    "        print(f\"{feature}: {value:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d66abb",
   "metadata": {},
   "source": [
    "## 7. Unit Tests\n",
    "\n",
    "Here are some unit tests to validate our data generation and model pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d281c242",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_data_generation():\n",
    "    \"\"\"Test that generated data meets expectations.\"\"\"\n",
    "    test_df = generate_synthetic_data(n=1000, seed=42)\n",
    "    \n",
    "    # Test shape\n",
    "    assert test_df.shape == (1000, 9), \"Wrong data shape\"\n",
    "    \n",
    "    # Test value ranges\n",
    "    assert test_df['age'].between(18, 95).all(), \"Age out of range\"\n",
    "    assert test_df['sex'].isin([0, 1]).all(), \"Invalid sex values\"\n",
    "    assert test_df['readmit_30d'].isin([0, 1]).all(), \"Invalid target values\"\n",
    "    \n",
    "    # Test reasonable readmission rate\n",
    "    assert 0.05 <= test_df['readmit_30d'].mean() <= 0.35, \"Unrealistic readmission rate\"\n",
    "    \n",
    "    print(\"Data generation tests passed!\")\n",
    "\n",
    "def test_model_pipeline():\n",
    "    \"\"\"Test model training and predictions.\"\"\"\n",
    "    # Generate small dataset\n",
    "    test_df = generate_synthetic_data(n=500, seed=42)\n",
    "    X = test_df.drop(columns=['readmit_30d'])\n",
    "    y = test_df['readmit_30d']\n",
    "    \n",
    "    # Train test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42\n",
    "    )\n",
    "    \n",
    "    # Scale\n",
    "    scaler = StandardScaler()\n",
    "    X_train_s = scaler.fit_transform(X_train)\n",
    "    X_test_s = scaler.transform(X_test)\n",
    "    \n",
    "    # Train\n",
    "    model = xgb.XGBClassifier(n_estimators=50, random_state=42)\n",
    "    model.fit(X_train_s, y_train)\n",
    "    \n",
    "    # Predict\n",
    "    y_pred = model.predict(X_test_s)\n",
    "    y_pred_proba = model.predict_proba(X_test_s)\n",
    "    \n",
    "    # Tests\n",
    "    assert y_pred.shape == y_test.shape, \"Wrong prediction shape\"\n",
    "    assert np.all(y_pred_proba >= 0) and np.all(y_pred_proba <= 1), \"Invalid probabilities\"\n",
    "    assert y_pred.dtype == y_test.dtype, \"Wrong prediction type\"\n",
    "    \n",
    "    print(\"Model pipeline tests passed!\")\n",
    "\n",
    "# Run tests\n",
    "test_data_generation()\n",
    "test_model_pipeline()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
